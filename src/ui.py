"""
UIæ¨¡å—
"""

import streamlit as st
from .document_processor import vectorize_document
from .index_manager import save_index, delete_index
from .search import extract_keywords, search_documents
from .qa_system import process_chatgpt_response, process_deepseek_response, process_local_deepseek_response
from .config import get_config, OLLAMA_DEEPSEEK_MODEL
import requests

def setup_page():
    """
    è®¾ç½®é¡µé¢åŸºæœ¬é…ç½®
    """
    st.set_page_config(
        page_title="AIçŸ¥è¯†é—®ç­”ç³»ç»Ÿ - by Huaiyuan Tan",
        page_icon="ğŸ§ ",
        layout="wide",
        initial_sidebar_state="collapsed",
        menu_items=None
    )
    
    # æ·»åŠ å¼€å‘è€…ä¿¡æ¯
    st.markdown("<h6 style='text-align: right; color: gray;'>å¼€å‘è€…: Huaiyuan Tan</h6>", unsafe_allow_html=True)
    
    # è‡ªå®šä¹‰æ ·å¼
    st.markdown("""
        <style>
        .reportview-container .main .block-container{
            padding-top: 1rem;
            padding-right: 1rem;
            padding-left: 1rem;
            padding-bottom: 1rem;
        }
        .stColumn {
            padding: 5px;
        }
        </style>
    """, unsafe_allow_html=True)

def show_model_status(chatgpt_status, deepseek_status):
    """
    æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
    """
    st.markdown("## ğŸ¤– æ¨¡å‹çŠ¶æ€")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### ChatGPT")
        if chatgpt_status['ok']:
            st.success(f"âœ… {chatgpt_status['model']}\n\nçŠ¶æ€ï¼š{chatgpt_status['message']}")
        else:
            st.error(f"âŒ {chatgpt_status['model']}\n\nçŠ¶æ€ï¼š{chatgpt_status['message']}")
    
    with col2:
        st.markdown("### Deepseek")
        if deepseek_status['ok']:
            st.success(f"âœ… {deepseek_status['model']}\n\nçŠ¶æ€ï¼š{deepseek_status['message']}")
        else:
            st.error(f"âŒ {deepseek_status['model']}\n\nçŠ¶æ€ï¼š{deepseek_status['message']}")
    
    with col3:
        st.markdown("### æœ¬åœ°DeepSeek")
        try:
            # è·å–OllamaåŸºç¡€URL
            ollama_url = get_config('OLLAMA_BASE_URL')
            # è·å–æ¨¡å‹åç§°
            model_name = get_config('OLLAMA_DEEPSEEK_MODEL')
            
            try:
                response = requests.get(f"{ollama_url}/api/tags")
                if response.status_code == 200:
                    models = response.json().get('models', [])
                    if model_name in [model['name'] for model in models]:
                        st.success(f"âœ… {model_name}\n\nçŠ¶æ€ï¼šè¿æ¥æ­£å¸¸")
                    else:
                        st.warning(f"âš ï¸ {model_name}\n\nçŠ¶æ€ï¼šæ¨¡å‹æœªåŠ è½½")
                else:
                    st.error(f"âŒ æœ¬åœ°DeepSeek\n\nçŠ¶æ€ï¼šè¿æ¥å¤±è´¥ - HTTP {response.status_code}")
            except requests.exceptions.RequestException as e:
                st.error(f"âŒ æœ¬åœ°DeepSeek\n\nçŠ¶æ€ï¼šè¿æ¥é”™è¯¯ - {str(e)}")
        except Exception as e:
            st.error("âŒ æœ¬åœ°DeepSeek\n\nçŠ¶æ€ï¼šé…ç½®é”™è¯¯")
    
    st.markdown("---")

def handle_file_upload(max_tokens=4096):
    """
    å¤„ç†æ–‡ä»¶ä¸Šä¼ 
    """
    st.subheader("æ–‡æ¡£ä¸Šä¼ ")
    uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡æ¡£", type=["pdf", "docx", "txt"], accept_multiple_files=True)
    
    if uploaded_files:
        for uploaded_file in uploaded_files:
            with st.spinner(f"æ­£åœ¨å¤„ç†æ–‡æ¡£: {uploaded_file.name}..."):
                chunks, index = vectorize_document(uploaded_file, max_tokens)
                st.session_state.file_indices[uploaded_file.name] = (chunks, index)
                save_index(uploaded_file.name, chunks, index)
            st.success(f"æ–‡æ¡£ {uploaded_file.name} å‘é‡åŒ–å¹¶æ·»åŠ åˆ°ç´¢å¼•ä¸­ï¼")

def show_document_list():
    """
    æ˜¾ç¤ºå·²å¤„ç†çš„æ–‡æ¡£åˆ—è¡¨
    """
    st.subheader("å·²å¤„ç†æ–‡æ¡£:")
    for file_name in list(st.session_state.file_indices.keys()):
        col1, col2 = st.columns([3, 1])
        with col1:
            st.write(f"â€¢ {file_name}")
        with col2:
            if st.button("åˆ é™¤", key=f"delete_{file_name}"):
                del st.session_state.file_indices[file_name]
                delete_index(file_name)
                st.success(f"æ–‡æ¡£ {file_name} å·²åˆ é™¤ï¼")
                st.rerun()

def handle_keyword_search():
    """
    å¤„ç†å…³é”®è¯æœç´¢
    """
    st.subheader("å…³é”®è¯æœç´¢")
    search_keywords = st.text_input("è¾“å…¥å…³é”®è¯ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼‰")
    if search_keywords:
        keywords = search_keywords.split()
        relevant_docs = search_documents(keywords, st.session_state.file_indices)
        if relevant_docs:
            st.write("ç›¸å…³æ–‡æ¡£ï¼š")
            for doc in relevant_docs:
                st.write(f"â€¢ {doc}")
            st.session_state.relevant_docs = relevant_docs
        else:
            st.write("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚")
            st.session_state.relevant_docs = None

def handle_qa(query, chatgpt_client, context_text):
    """
    å¤„ç†é—®ç­”
    """
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### ChatGPTå›ç­”")
        chatgpt_placeholder = st.empty()
        chatgpt_placeholder.markdown("""
        <div style='background-color: #f0f2f6; padding: 15px; border-radius: 5px;'>
            <div class="loading">æ­£åœ¨å¤„ç†ä¸­...</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("### DeepSeekå›ç­”")
        
        # åˆ›å»ºä¸€ä¸ªé»˜è®¤æ”¶èµ·çš„expanderç”¨äºæ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
        thinking_expander = st.expander("ğŸ¤” æŸ¥çœ‹Deepseekæ¨ç†è¿‡ç¨‹", expanded=False)
        with thinking_expander:
            thinking_container = st.empty()
            thinking_container.markdown("""
            <div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>
                <p style='color: #666; margin-bottom: 10px;'>ç­‰å¾…å¤„ç†ä¸­...</p>
            </div>
            """, unsafe_allow_html=True)
        
        # åˆ›å»ºä¸€ä¸ªç©ºçš„å®¹å™¨ç”¨äºæ˜¾ç¤ºç­”æ¡ˆ
        deepseek_answer_container = st.empty()
        deepseek_answer_container.markdown("""
        <div style='background-color: #e6f3ff; padding: 15px; border-radius: 5px;'>
            <div class="loading">ç­‰å¾…å¤„ç†ä¸­...</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("### æœ¬åœ°DeepSeekå›ç­”")
        
        # åˆ›å»ºä¸€ä¸ªé»˜è®¤æ”¶èµ·çš„expanderç”¨äºæ˜¾ç¤ºæœ¬åœ°æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹
        local_thinking_expander = st.expander("ğŸ¤” æŸ¥çœ‹æœ¬åœ°Deepseekæ¨ç†è¿‡ç¨‹", expanded=False)
        with local_thinking_expander:
            local_thinking_container = st.empty()
            local_thinking_container.markdown("""
            <div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>
                <p style='color: #666; margin-bottom: 10px;'>ç­‰å¾…å¤„ç†ä¸­...</p>
            </div>
            """, unsafe_allow_html=True)
        
        # åˆ›å»ºä¸€ä¸ªç©ºçš„å®¹å™¨ç”¨äºæ˜¾ç¤ºæœ¬åœ°æ¨¡å‹çš„ç­”æ¡ˆ
        local_deepseek_answer_container = st.empty()
        local_deepseek_answer_container.markdown("""
        <div style='background-color: #e6f3ff; padding: 15px; border-radius: 5px;'>
            <div class="loading">ç­‰å¾…å¤„ç†ä¸­...</div>
        </div>
        """, unsafe_allow_html=True)
    
    # åˆå§‹åŒ–è¿”å›å€¼
    chatgpt_result = ("", "")
    deepseek_result = ("", "")
    local_deepseek_result = ("", "")
    
    # å¤„ç†ChatGPTå›ç­”
    try:
        chatgpt_answer, chatgpt_excerpt = process_chatgpt_response(chatgpt_client, context_text, query)
        chatgpt_placeholder.markdown(f"""
        <div style='background-color: #f0f2f6; padding: 15px; border-radius: 5px;'>
            {chatgpt_answer}
        </div>
        """, unsafe_allow_html=True)
        chatgpt_result = (chatgpt_answer, chatgpt_excerpt)
    except Exception as e:
        chatgpt_placeholder.markdown(f"""
        <div style='background-color: #ffe6e6; padding: 15px; border-radius: 5px;'>
            ChatGPTæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(e)}
        </div>
        """, unsafe_allow_html=True)
    
    # æ›´æ–°DeepseekçŠ¶æ€ä¸ºæ­£åœ¨å¤„ç†
    thinking_container.markdown("""
    <div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>
        <p style='color: #666; margin-bottom: 10px;'>æ­£åœ¨æ¨ç†ä¸­...</p>
    </div>
    """, unsafe_allow_html=True)
    deepseek_answer_container.markdown("""
    <div style='background-color: #e6f3ff; padding: 15px; border-radius: 5px;'>
        <div class="loading">æ­£åœ¨å¤„ç†ä¸­...</div>
    </div>
    """, unsafe_allow_html=True)
    
    # å¤„ç†Deepseekå›ç­”
    try:
        deepseek_answer, deepseek_excerpt, thinking_steps = process_deepseek_response(
            context_text, 
            query, 
            deepseek_answer_container,
            thinking_container
        )
        deepseek_result = (deepseek_answer, deepseek_excerpt)
    except Exception as e:
        deepseek_answer_container.markdown(f"""
        <div style='background-color: #ffe6e6; padding: 15px; border-radius: 5px;'>
            DeepseekæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(e)}
        </div>
        """, unsafe_allow_html=True)
        thinking_container.markdown("""
        <div style='background-color: #ffe6e6; padding: 10px; border-radius: 5px;'>
            <p style='color: #666;'>æ¨ç†è¿‡ç¨‹ä¸å¯ç”¨</p>
        </div>
        """, unsafe_allow_html=True)
    
    # æ›´æ–°æœ¬åœ°DeepseekçŠ¶æ€ä¸ºæ­£åœ¨å¤„ç†
    local_thinking_container.markdown("""
    <div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>
        <p style='color: #666; margin-bottom: 10px;'>æ­£åœ¨æ¨ç†ä¸­...</p>
    </div>
    """, unsafe_allow_html=True)
    local_deepseek_answer_container.markdown("""
    <div style='background-color: #e6f3ff; padding: 15px; border-radius: 5px;'>
        <div class="loading">æ­£åœ¨å¤„ç†ä¸­...</div>
    </div>
    """, unsafe_allow_html=True)
    
    # å¤„ç†æœ¬åœ°DeepSeekå›ç­”
    try:
        local_deepseek_answer, local_deepseek_excerpt, local_thinking_steps = process_local_deepseek_response(
            context_text,
            query,
            local_deepseek_answer_container,
            local_thinking_container
        )
        local_deepseek_result = (local_deepseek_answer, local_deepseek_excerpt)
    except Exception as e:
        local_deepseek_answer_container.markdown(f"""
        <div style='background-color: #ffe6e6; padding: 15px; border-radius: 5px;'>
            æœ¬åœ°DeepseekæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(e)}
        </div>
        """, unsafe_allow_html=True)
        local_thinking_container.markdown("""
        <div style='background-color: #ffe6e6; padding: 10px; border-radius: 5px;'>
            <p style='color: #666;'>æ¨ç†è¿‡ç¨‹ä¸å¯ç”¨</p>
        </div>
        """, unsafe_allow_html=True)
    
    return chatgpt_result, deepseek_result 