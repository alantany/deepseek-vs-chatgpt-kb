"""
UIæ¨¡å—
"""

import streamlit as st
from .document_processor import vectorize_document
from .index_manager import save_index, delete_index
from .search import extract_keywords, search_documents
from .qa_system import process_chatgpt_response, process_deepseek_response

def setup_page():
    """
    è®¾ç½®é¡µé¢åŸºæœ¬é…ç½®
    """
    st.set_page_config(
        page_title="AIçŸ¥è¯†é—®ç­”ç³»ç»Ÿ - by Huaiyuan Tan",
        page_icon="ğŸ§ ",
        layout="wide",
        initial_sidebar_state="collapsed",
        menu_items=None
    )
    
    # æ·»åŠ å¼€å‘è€…ä¿¡æ¯
    st.markdown("<h6 style='text-align: right; color: gray;'>å¼€å‘è€…: Huaiyuan Tan</h6>", unsafe_allow_html=True)
    
    # è‡ªå®šä¹‰æ ·å¼
    st.markdown("""
        <style>
        .reportview-container .main .block-container{
            padding-top: 1rem;
            padding-right: 1rem;
            padding-left: 1rem;
            padding-bottom: 1rem;
        }
        .stColumn {
            padding: 5px;
        }
        </style>
    """, unsafe_allow_html=True)

def show_model_status(chatgpt_status, deepseek_status):
    """
    æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
    """
    st.markdown("## ğŸ¤– æ¨¡å‹çŠ¶æ€")
    status_col1, status_col2 = st.columns(2)
    
    with status_col1:
        st.markdown("### ChatGPT")
        if chatgpt_status['ok']:
            st.success(f"âœ… {chatgpt_status['model']}\n\nçŠ¶æ€ï¼š{chatgpt_status['message']}")
        else:
            st.error(f"âŒ {chatgpt_status['model']}\n\nçŠ¶æ€ï¼š{chatgpt_status['message']}")
    
    with status_col2:
        st.markdown("### DeepSeek")
        if deepseek_status['ok']:
            st.success(f"âœ… {deepseek_status['model']}\n\nçŠ¶æ€ï¼š{deepseek_status['message']}")
        else:
            st.error(f"âŒ {deepseek_status['model']}\n\nçŠ¶æ€ï¼š{deepseek_status['message']}")
    
    st.markdown("---")

def handle_file_upload(max_tokens=4096):
    """
    å¤„ç†æ–‡ä»¶ä¸Šä¼ 
    """
    st.subheader("æ–‡æ¡£ä¸Šä¼ ")
    uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡æ¡£", type=["pdf", "docx", "txt"], accept_multiple_files=True)
    
    if uploaded_files:
        for uploaded_file in uploaded_files:
            with st.spinner(f"æ­£åœ¨å¤„ç†æ–‡æ¡£: {uploaded_file.name}..."):
                chunks, index = vectorize_document(uploaded_file, max_tokens)
                st.session_state.file_indices[uploaded_file.name] = (chunks, index)
                save_index(uploaded_file.name, chunks, index)
            st.success(f"æ–‡æ¡£ {uploaded_file.name} å‘é‡åŒ–å¹¶æ·»åŠ åˆ°ç´¢å¼•ä¸­ï¼")

def show_document_list():
    """
    æ˜¾ç¤ºå·²å¤„ç†çš„æ–‡æ¡£åˆ—è¡¨
    """
    st.subheader("å·²å¤„ç†æ–‡æ¡£:")
    for file_name in list(st.session_state.file_indices.keys()):
        col1, col2 = st.columns([3, 1])
        with col1:
            st.write(f"â€¢ {file_name}")
        with col2:
            if st.button("åˆ é™¤", key=f"delete_{file_name}"):
                del st.session_state.file_indices[file_name]
                delete_index(file_name)
                st.success(f"æ–‡æ¡£ {file_name} å·²åˆ é™¤ï¼")
                st.rerun()

def handle_keyword_search():
    """
    å¤„ç†å…³é”®è¯æœç´¢
    """
    st.subheader("å…³é”®è¯æœç´¢")
    search_keywords = st.text_input("è¾“å…¥å…³é”®è¯ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼‰")
    if search_keywords:
        keywords = search_keywords.split()
        relevant_docs = search_documents(keywords, st.session_state.file_indices)
        if relevant_docs:
            st.write("ç›¸å…³æ–‡æ¡£ï¼š")
            for doc in relevant_docs:
                st.write(f"â€¢ {doc}")
            st.session_state.relevant_docs = relevant_docs
        else:
            st.write("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚")
            st.session_state.relevant_docs = None

def handle_qa(query, chatgpt_client, context_text):
    """
    å¤„ç†é—®ç­”
    """
    left_col, right_col = st.columns(2)
    
    with left_col:
        st.markdown("### ChatGPTå›ç­”")
        chatgpt_placeholder = st.empty()
        chatgpt_placeholder.markdown("""
        <div style='background-color: #f0f2f6; padding: 15px; border-radius: 5px;'>
            <div class="loading">æ­£åœ¨ç­‰å¾…ChatGPTå›ç­”...</div>
        </div>
        """, unsafe_allow_html=True)
    
    with right_col:
        st.markdown("### Deepseekå›ç­”")
        
        # åˆ›å»ºä¸€ä¸ªé»˜è®¤æ”¶èµ·çš„expanderç”¨äºæ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
        thinking_expander = st.expander("ğŸ¤” æŸ¥çœ‹Deepseekæ¨ç†è¿‡ç¨‹", expanded=False)
        with thinking_expander:
            thinking_container = st.empty()
            thinking_container.markdown("""
            <div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>
                <p style='color: #666; margin-bottom: 10px;'>ç­‰å¾…å¼€å§‹æ¨ç†...</p>
            </div>
            """, unsafe_allow_html=True)
        
        # åˆ›å»ºä¸€ä¸ªç©ºçš„å®¹å™¨ç”¨äºæ˜¾ç¤ºç­”æ¡ˆ
        deepseek_answer_container = st.empty()
        deepseek_answer_container.markdown("""
        <div style='background-color: #e6f3ff; padding: 15px; border-radius: 5px;'>
            <div class="loading">ç­‰å¾…å¼€å§‹å¤„ç†...</div>
        </div>
        """, unsafe_allow_html=True)
    
    # å¤„ç†ChatGPTå›ç­”
    chatgpt_answer, chatgpt_excerpt = process_chatgpt_response(chatgpt_client, context_text, query)
    chatgpt_placeholder.markdown(f"""
    <div style='background-color: #f0f2f6; padding: 15px; border-radius: 5px;'>
        {chatgpt_answer}
    </div>
    """, unsafe_allow_html=True)
    
    # å¤„ç†Deepseekå›ç­”
    deepseek_answer, deepseek_excerpt, thinking_steps = process_deepseek_response(
        context_text, 
        query, 
        deepseek_answer_container,
        thinking_container
    )
    
    return (chatgpt_answer, chatgpt_excerpt), (deepseek_answer, deepseek_excerpt) 