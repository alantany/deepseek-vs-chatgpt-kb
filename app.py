"""
AIçŸ¥è¯†é—®ç­”ç³»ç»Ÿ

ä½¿ç”¨æ–¹æ³•ï¼š
1. ä¸Šä¼ æ–‡æ¡£ï¼ˆæ”¯æŒPDFã€DOCXã€TXTæ ¼å¼ï¼‰
2. è¾“å…¥é—®é¢˜
3. è·å–AIå›ç­”
"""

import streamlit as st
import sys
import os
from openai import OpenAI
from sentence_transformers import SentenceTransformer
import PyPDF2
import docx
import faiss
import tiktoken
import pickle
import numpy as np
from collections import Counter
import pandas as pd
import jieba
from dotenv import load_dotenv
import requests
import re

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def get_config(key: str, default: str = None) -> str:
    """
    è·å–é…ç½®å€¼ï¼Œä¼˜å…ˆä»Streamlit secretsè·å–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä»ç¯å¢ƒå˜é‡è·å–
    """
    try:
        return st.secrets[key]
    except KeyError:
        return os.getenv(key, default)

# æ›¿æ¢ç¯å¢ƒå˜é‡æ£€æŸ¥éƒ¨åˆ†
required_configs = {
    'OPENAI_API_KEY': 'ç”¨äºChatGPTçš„APIå¯†é’¥',
    'OPENAI_API_BASE': 'ChatGPTçš„APIåŸºç¡€URL',
    'DEEPSEEK_API_KEY': 'ç”¨äºDeepseekçš„APIå¯†é’¥',
    'DEEPSEEK_API_BASE': 'Deepseekçš„APIåŸºç¡€URL'
}

missing_configs = []
for config, description in required_configs.items():
    if not get_config(config):
        missing_configs.append(f"{config} ({description})")

if missing_configs:
    st.error("""
    ### ç¼ºå°‘å¿…è¦çš„é…ç½®
    è¯·åœ¨ä»¥ä¸‹ä½ç½®ä¹‹ä¸€é…ç½®è¿™äº›å€¼ï¼š
    1. Streamlit Cloudéƒ¨ç½²ï¼šåœ¨é¡¹ç›®è®¾ç½®ä¸­æ·»åŠ  secrets.toml
    2. æœ¬åœ°å¼€å‘ï¼šåœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶
    
    ç¼ºå°‘çš„é…ç½®ï¼š
    """ + "\n".join(missing_configs))
    st.stop()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="AIçŸ¥è¯†é—®ç­”ç³»ç»Ÿ - by Huaiyuan Tan",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="collapsed",
    menu_items=None
)

# æ·»åŠ å¼€å‘è€…ä¿¡æ¯
st.markdown("<h6 style='text-align: right; color: gray;'>å¼€å‘è€…: Huaiyuan Tan</h6>", unsafe_allow_html=True)

# éšè— Streamlit é»˜è®¤çš„èœå•ã€é¡µè„šå’Œ Deploy æŒ‰é’®
hide_streamlit_style = """
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .stDeployButton {display: none;}
    header {visibility: hidden;}
    </style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
chatgpt_client = OpenAI(
    api_key=get_config("OPENAI_API_KEY"),
    base_url=get_config("OPENAI_API_BASE"),
)

# å¯¹Deepseekçš„URLè¿›è¡Œå¤„ç†ï¼Œç¡®ä¿ä¸åŒ…å«chat/completions
deepseek_base_url = get_config("DEEPSEEK_API_BASE")
if deepseek_base_url and deepseek_base_url.endswith("/chat/completions"):
    deepseek_base_url = deepseek_base_url.replace("/chat/completions", "")

# åˆå§‹åŒ–Deepseekå®¢æˆ·ç«¯
deepseek_client = OpenAI(
    api_key=get_config("DEEPSEEK_API_KEY"),
    base_url=deepseek_base_url,
    default_headers={
        "Content-Type": "application/json",
        "Authorization": f"Bearer {get_config('DEEPSEEK_API_KEY')}"
    }
)

def test_api_connection(client, model_name):
    """æµ‹è¯•APIè¿æ¥çŠ¶æ€"""
    try:
        st.write(f"æ­£åœ¨æµ‹è¯• {model_name} APIè¿æ¥...")
        
        if model_name == "Deepseek":
            # ä½¿ç”¨é…ç½®å€¼è€Œä¸æ˜¯ç¡¬ç¼–ç 
            API_URL = f"{get_config('DEEPSEEK_API_BASE')}/chat/completions"
            API_KEY = get_config("DEEPSEEK_API_KEY")
            MODEL = "deepseek-ai/DeepSeek-R1"
            
            st.write(f"ä½¿ç”¨çš„APIåŸºç¡€URL: {API_URL}")
            st.write(f"ä½¿ç”¨çš„æ¨¡å‹: {MODEL}")
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {API_KEY}"
            }
            data = {
                "model": MODEL,
                "messages": [{"role": "user", "content": "Hello"}],
                "max_tokens": 10
            }
            response = requests.post(
                API_URL,
                headers=headers,
                json=data
            )
            if response.status_code != 200:
                raise Exception(f"APIè¿”å›é”™è¯¯: {response.text}")
            response_data = response.json()
            model_info = f"{model_name} ({response_data['model']})" if 'model' in response_data else model_name
            return True, "è¿æ¥æ­£å¸¸", model_info
        else:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": "Hello"}],
                max_tokens=10
            )
            model_info = f"{model_name} ({response.model})" if hasattr(response, 'model') else model_name
            return True, "è¿æ¥æ­£å¸¸", model_info
    except Exception as e:
        st.error(f"{model_name} è¿æ¥æµ‹è¯•é”™è¯¯: {str(e)}")
        if model_name == "Deepseek":
            st.error(f"Deepseeké…ç½®ä¿¡æ¯ï¼š\nURL: {API_URL}\næ¨¡å‹: {MODEL}")
        return False, f"è¿æ¥é”™è¯¯: {str(e)}", model_name

# æµ‹è¯•APIè¿æ¥çŠ¶æ€
if 'api_status' not in st.session_state:
    st.session_state.api_status = {}

# åœ¨é¡µé¢é¡¶éƒ¨æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
st.markdown("## ğŸ¤– æ¨¡å‹çŠ¶æ€")

# åˆ›å»ºä¸¤åˆ—å¸ƒå±€æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
status_col1, status_col2 = st.columns(2)

# æµ‹è¯•å¹¶æ˜¾ç¤ºChatGPTçŠ¶æ€
with status_col1:
    st.markdown("### ChatGPT")
    chatgpt_ok, chatgpt_msg, chatgpt_model = test_api_connection(chatgpt_client, "ChatGPT")
    st.session_state.api_status['chatgpt'] = {
        'ok': chatgpt_ok,
        'message': chatgpt_msg,
        'model': chatgpt_model
    }
    if chatgpt_ok:
        st.success(f"âœ… {chatgpt_model}\n\nçŠ¶æ€ï¼š{chatgpt_msg}")
    else:
        st.error(f"âŒ {chatgpt_model}\n\nçŠ¶æ€ï¼š{chatgpt_msg}")

# æµ‹è¯•å¹¶æ˜¾ç¤ºDeepseekçŠ¶æ€
with status_col2:
    st.markdown("### Deepseek")
    deepseek_ok, deepseek_msg, deepseek_model = test_api_connection(deepseek_client, "Deepseek")
    st.session_state.api_status['deepseek'] = {
        'ok': deepseek_ok,
        'message': deepseek_msg,
        'model': deepseek_model
    }
    if deepseek_ok:
        st.success(f"âœ… {deepseek_model}\n\nçŠ¶æ€ï¼š{deepseek_msg}")
    else:
        st.error(f"âŒ {deepseek_model}\n\nçŠ¶æ€ï¼š{deepseek_msg}")

st.markdown("---")

@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

model = load_model()

# è®¡ç®—tokenæ•°é‡
def num_tokens_from_string(string: str) -> int:
    encoding = tiktoken.encoding_for_model("gpt-4o-mini")
    return len(encoding.encode(string))

# æ–‡æ¡£å‘é‡åŒ–æ¨¡å—
def vectorize_document(file, max_tokens):
    text = ""
    if file.type == "application/pdf":
        pdf_reader = PyPDF2.PdfReader(file)
        for page in pdf_reader.pages:
            text += page.extract_text()
    elif file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        doc = docx.Document(file)
        for para in doc.paragraphs:
            text += para.text + "\n"
    else:
        text = file.getvalue().decode("utf-8")
    
    chunks = []
    current_chunk = ""
    for sentence in text.split('.'):
        if num_tokens_from_string(current_chunk + sentence) > max_tokens:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = sentence
        else:
            current_chunk += sentence + '.'
    if current_chunk:
        chunks.append(current_chunk)
    
    vectors = model.encode(chunks)
    index = faiss.IndexFlatL2(384)  # 384æ˜¯å‘é‡ç»´åº¦,æ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´
    index.add(vectors)
    return chunks, index

# æå–å…³é”®è¯
def extract_keywords(text, top_k=5):
    words = jieba.cut(text)
    word_count = Counter(words)
    # è¿‡æ»¤æ‰åœç”¨è¯å’Œå•ä¸ªå­—ç¬¦
    keywords = [word for word, count in word_count.most_common(top_k*2) if len(word) > 1]
    return keywords[:top_k]

# åŸºäºå…³é”®è¯æœç´¢æ–‡æ¡£
def search_documents(keywords, file_indices):
    relevant_docs = []
    for file_name, (chunks, _) in file_indices.items():
        doc_content = ' '.join(chunks)
        if any(keyword in doc_content for keyword in keywords):
            relevant_docs.append(file_name)
    return relevant_docs

# çŸ¥è¯†é—®ç­”æ¨¡å—
def rag_qa(query, file_indices, relevant_docs=None):
    try:
        st.write("å¼€å§‹å¤„ç†æŸ¥è¯¢...")
        keywords = extract_keywords(query)
        if relevant_docs is None:
            relevant_docs = search_documents(keywords, file_indices)
        
        st.write(f"æ‰¾åˆ°ç›¸å…³æ–‡æ¡£æ•°é‡: {len(relevant_docs)}")
        
        if not relevant_docs:
            return {
                'chatgpt': "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚è¯·å°è¯•ä½¿ç”¨ä¸åŒçš„å…³é”®è¯ã€‚",
                'deepseek': "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚è¯·å°è¯•ä½¿ç”¨ä¸åŒçš„å…³é”®è¯ã€‚"
            }, [], ""

        all_chunks = []
        chunk_to_file = {}
        combined_index = faiss.IndexFlatL2(384)
        
        offset = 0
        for file_name in relevant_docs:
            if file_name in file_indices:
                chunks, index = file_indices[file_name]
                all_chunks.extend(chunks)
                for i in range(len(chunks)):
                    chunk_to_file[offset + i] = file_name
                if index.ntotal > 0:
                    vectors = index.reconstruct_n(0, index.ntotal)
                    combined_index.add(vectors.astype(np.float32))
                offset += len(chunks)

        if not all_chunks:
            return {
                'chatgpt': "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è¯·ç¡®ä¿å·²ä¸Šä¼ æ–‡æ¡£ã€‚",
                'deepseek': "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è¯·ç¡®ä¿å·²ä¸Šä¼ æ–‡æ¡£ã€‚"
            }, [], ""

        query_vector = model.encode([query])
        D, I = combined_index.search(query_vector.astype(np.float32), k=3)
        context = []
        context_with_sources = []
        for i in I[0]:
            if 0 <= i < len(all_chunks):
                chunk = all_chunks[i]
                context.append(chunk)
                file_name = chunk_to_file.get(i, "æœªçŸ¥æ–‡ä»¶")
                context_with_sources.append((file_name, chunk))

        context_text = "\n".join(context)
        
        # ç¡®ä¿æ€»tokenæ•°ä¸è¶…è¿‡4096
        max_context_tokens = 3000
        original_length = len(context_text)
        while num_tokens_from_string(context_text) > max_context_tokens:
            context_text = context_text[:int(len(context_text)*0.9)]
        if len(context_text) < original_length:
            st.write(f"æˆªæ–­ä¸Šä¸‹æ–‡ä» {original_length} åˆ° {len(context_text)} å­—ç¬¦")
        
        if not context_text:
            return {
                'chatgpt': "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚",
                'deepseek': "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
            }, [], ""

        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
        left_col, right_col = st.columns(2)
        
        # åˆ›å»ºå ä½ç¬¦
        with left_col:
            st.markdown("### ChatGPTå›ç­”")
            chatgpt_placeholder = st.empty()
            chatgpt_placeholder.markdown("""
            <div style='background-color: #f0f2f6; padding: 15px; border-radius: 5px;'>
                æ­£åœ¨å¤„ç†ChatGPTå›ç­”...
            </div>
            """, unsafe_allow_html=True)
        
        with right_col:
            st.markdown("### Deepseekå›ç­”")
            deepseek_placeholder = st.empty()
            deepseek_placeholder.markdown("""
            <div style='background-color: #e6f3ff; padding: 15px; border-radius: 5px;'>
                ç­‰å¾…å¤„ç†Deepseekå›ç­”...
            </div>
            """, unsafe_allow_html=True)

        responses = {'chatgpt': "", 'deepseek': ""}
        excerpts = {'chatgpt': "", 'deepseek': ""}

        # å…ˆå¤„ç†ChatGPTå›ç­”
        st.write("æ­£åœ¨è°ƒç”¨ChatGPT API...")
        if st.session_state.api_status['chatgpt']['ok']:
            try:
                chatgpt_response = chatgpt_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç»™å®šçš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å§‹ç»ˆä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œæ— è®ºé—®é¢˜æ˜¯ä»€ä¹ˆè¯­è¨€ã€‚åœ¨å›ç­”ä¹‹åï¼Œè¯·åŠ¡å¿…æä¾›ä¸€æ®µæœ€ç›¸å…³çš„åŸæ–‡æ‘˜å½•ï¼Œä»¥'ç›¸å…³åŸæ–‡ï¼š'ä¸ºå‰ç¼€ã€‚"},
                        {"role": "user", "content": f"ä¸Šä¸‹æ–‡: {context_text}\n\né—®é¢˜: {query}\n\nè¯·æä¾›ä½ çš„å›ç­”ç„¶ååœ¨å›ç­”åé¢é™„ä¸Šç›¸å…³çš„åŸæ–‡æ‘˜å½•ï¼Œä»¥'ç›¸å…³åŸæ–‡ï¼š'ä¸ºå‰ç¼€ã€‚"}
                    ]
                )
                chatgpt_answer = chatgpt_response.choices[0].message.content
                st.write("ChatGPT APIè°ƒç”¨æˆåŠŸ")
                
                if "ç›¸å…³åŸæ–‡ï¼š" in chatgpt_answer:
                    chatgpt_parts = chatgpt_answer.split("ç›¸å…³åŸæ–‡ï¼š", 1)
                    responses['chatgpt'] = chatgpt_parts[0].strip()
                    excerpts['chatgpt'] = chatgpt_parts[1].strip()
                else:
                    responses['chatgpt'] = chatgpt_answer.strip()
                
                # ç«‹å³æ›´æ–°ChatGPTå›ç­”
                chatgpt_placeholder.markdown(f"""
                <div style='background-color: #f0f2f6; padding: 15px; border-radius: 5px;'>
                    {responses['chatgpt']}
                </div>
                """, unsafe_allow_html=True)
            except Exception as e:
                st.error(f"ChatGPT APIè°ƒç”¨å‡ºé”™: {str(e)}")
                responses['chatgpt'] = "APIè°ƒç”¨å‡ºé”™ï¼Œè¯·ç¨åé‡è¯•"
                chatgpt_placeholder.error("è·å–ChatGPTå›ç­”å¤±è´¥")
        else:
            responses['chatgpt'] = "ChatGPT API æœªè¿æ¥"
            chatgpt_placeholder.error("ChatGPT API æœªè¿æ¥")

        # å†å¤„ç†Deepseekå›ç­”
        st.write("æ­£åœ¨è°ƒç”¨Deepseek API...")
        if st.session_state.api_status['deepseek']['ok']:
            try:
                # ä½¿ç”¨ç¡¬ç¼–ç çš„é…ç½®
                API_URL = f"{get_config('DEEPSEEK_API_BASE')}/chat/completions"
                API_KEY = get_config("DEEPSEEK_API_KEY")
                MODEL = "deepseek-ai/DeepSeek-R1"
                
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {API_KEY}"
                }
                data = {
                    "model": MODEL,
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç»™å®šçš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚å§‹ç»ˆä½¿ç”¨ä¸­æ–‡å›ç­”ï¼Œæ— è®ºé—®é¢˜æ˜¯ä»€ä¹ˆè¯­è¨€ã€‚åœ¨å›ç­”ä¹‹åï¼Œè¯·åŠ¡å¿…æä¾›ä¸€æ®µæœ€ç›¸å…³çš„åŸæ–‡æ‘˜å½•ï¼Œä»¥'ç›¸å…³åŸæ–‡ï¼š'ä¸ºå‰ç¼€ã€‚"},
                        {"role": "user", "content": f"ä¸Šä¸‹æ–‡: {context_text}\n\né—®é¢˜: {query}\n\nè¯·æä¾›ä½ çš„å›ç­”ç„¶ååœ¨å›ç­”åé¢é™„ä¸Šç›¸å…³çš„åŸæ–‡æ‘˜å½•ï¼Œä»¥'ç›¸å…³åŸæ–‡ï¼š'ä¸ºå‰ç¼€ã€‚"}
                    ],
                    "max_tokens": 1000
                }
                
                response = requests.post(
                    API_URL,
                    headers=headers,
                    json=data
                )
                
                if response.status_code != 200:
                    error_detail = response.json() if response.text else "æ— è¯¦ç»†é”™è¯¯ä¿¡æ¯"
                    st.write(f"é”™è¯¯è¯¦æƒ…: {error_detail}")
                    raise Exception(f"APIè¿”å›é”™è¯¯: {error_detail}")
                
                response_data = response.json()
                deepseek_answer = response_data['choices'][0]['message']['content']
                st.write("Deepseek APIè°ƒç”¨æˆåŠŸ")
                
                # è§£ææ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆ
                think_pattern = r'/think/(.*?)/think/'
                think_matches = re.findall(think_pattern, deepseek_answer, re.DOTALL)
                
                # ç§»é™¤æ‰€æœ‰æ¨ç†è¿‡ç¨‹ï¼Œå¾—åˆ°æœ€ç»ˆç­”æ¡ˆ
                final_answer = re.sub(think_pattern, '', deepseek_answer, flags=re.DOTALL)
                
                # å¤„ç†ç›¸å…³åŸæ–‡
                if "ç›¸å…³åŸæ–‡ï¼š" in final_answer:
                    answer_parts = final_answer.split("ç›¸å…³åŸæ–‡ï¼š", 1)
                    responses['deepseek'] = answer_parts[0].strip()
                    excerpts['deepseek'] = answer_parts[1].strip()
                else:
                    responses['deepseek'] = final_answer.strip()
                
                # æ›´æ–°Deepseekå›ç­”æ˜¾ç¤º
                deepseek_content = f"""
                <div style='background-color: #e6f3ff; padding: 15px; border-radius: 5px;'>
                    {responses['deepseek']}
                </div>
                """
                deepseek_placeholder.markdown(deepseek_content, unsafe_allow_html=True)
                
                # å¦‚æœæœ‰æ¨ç†è¿‡ç¨‹ï¼Œæ˜¾ç¤ºåœ¨expanderä¸­
                if think_matches:
                    with deepseek_placeholder.expander("æŸ¥çœ‹æ¨ç†è¿‡ç¨‹", expanded=False):
                        for i, think in enumerate(think_matches, 1):
                            st.markdown(f"""
                            <div style='background-color: #f0f2f6; padding: 15px; border-radius: 5px; margin-bottom: 10px;'>
                                <strong>æ¨ç†æ­¥éª¤ {i}:</strong><br>
                                {think.strip()}
                            </div>
                            """, unsafe_allow_html=True)
            except Exception as e:
                st.error(f"Deepseek APIè°ƒç”¨å‡ºé”™: {str(e)}")
                st.error(f"Deepseeké…ç½®ä¿¡æ¯ï¼š\nURL: {API_URL}\næ¨¡å‹: {MODEL}")
                responses['deepseek'] = "APIè°ƒç”¨å‡ºé”™ï¼Œè¯·ç¨åé‡è¯•"
                deepseek_placeholder.error("è·å–Deepseekå›ç­”å¤±è´¥")
        else:
            responses['deepseek'] = "Deepseek API æœªè¿æ¥"
            deepseek_placeholder.error("Deepseek API æœªè¿æ¥")

        # æ˜¾ç¤ºæ¥æºæ–‡æ¡£
        if sources:
            st.markdown("### æ¥æºæ–‡æ¡£")
            for file_name, context in sources:
                with st.expander(f"ğŸ“„ {file_name}"):
                    st.write(context)
        
        # æ˜¾ç¤ºç›¸å…³åŸæ–‡
        excerpt = excerpts['chatgpt'] or excerpts['deepseek']
        if excerpt:
            st.markdown("### ç›¸å…³åŸæ–‡")
            st.markdown(f"""
            <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border: 1px solid #dee2e6;'>
                {excerpt}
            </div>
            """, unsafe_allow_html=True)

        return responses, sources, excerpt

    except Exception as e:
        st.error(f"å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        st.error(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
        return {
            'chatgpt': "å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•",
            'deepseek': "å¤„ç†æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•"
        }, [], ""

# ä¿å­˜ç´¢å¼•å’Œchunks
def save_index(file_name, chunks, index):
    if not os.path.exists('indices'):
        os.makedirs('indices')
    with open(f'indices/{file_name}.pkl', 'wb') as f:
        pickle.dump((chunks, index), f)
    # ä¿å­˜æ–‡ä»¶ååˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­
    file_list_path = 'indices/file_list.txt'
    if os.path.exists(file_list_path):
        with open(file_list_path, 'r') as f:
            file_list = f.read().splitlines()
    else:
        file_list = []
    if file_name not in file_list:
        file_list.append(file_name)
        with open(file_list_path, 'w') as f:
            f.write('\n'.join(file_list))

# åŠ è½½æ‰€æœ‰ä¿å­˜çš„ç´¢å¼•
def load_all_indices():
    file_indices = {}
    file_list_path = 'indices/file_list.txt'
    if os.path.exists(file_list_path):
        with open(file_list_path, 'r') as f:
            file_list = f.read().splitlines()
        for file_name in file_list:
            file_path = f'indices/{file_name}.pkl'
            if os.path.exists(file_path):
                with open(file_path, 'rb') as f:
                    chunks, index = pickle.load(f)
                file_indices[file_name] = (chunks, index)
    return file_indices

def delete_index(file_name):
    if os.path.exists(f'indices/{file_name}.pkl'):
        os.remove(f'indices/{file_name}.pkl')
    file_list_path = 'indices/file_list.txt'
    if os.path.exists(file_list_path):
        with open(file_list_path, 'r') as f:
            file_list = f.read().splitlines()
        if file_name in file_list:
            file_list.remove(file_name)
            with open(file_list_path, 'w') as f:
                f.write('\n'.join(file_list))

def main():
    st.markdown("""
    <style>
    .reportview-container .main .block-container{
        padding-top: 1rem;
        padding-right: 1rem;
        padding-left: 1rem;
        padding-bottom: 1rem;
    }
    .stColumn {
        padding: 5px;
    }
    </style>
    """, unsafe_allow_html=True)

    st.title("AIçŸ¥è¯†é—®ç­”ç³»ç»Ÿ")

    # åˆå§‹åŒ– session state
    if "file_indices" not in st.session_state:
        st.session_state.file_indices = load_all_indices()

    # æ–‡æ¡£ä¸Šä¼ éƒ¨åˆ†
    st.subheader("æ–‡æ¡£ä¸Šä¼ ")
    
    max_tokens = 4096

    uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡æ¡£", type=["pdf", "docx", "txt"], accept_multiple_files=True)

    if uploaded_files:
        for uploaded_file in uploaded_files:
            with st.spinner(f"æ­£åœ¨å¤„ç†æ–‡æ¡£: {uploaded_file.name}..."):
                chunks, index = vectorize_document(uploaded_file, max_tokens)
                st.session_state.file_indices[uploaded_file.name] = (chunks, index)
                save_index(uploaded_file.name, chunks, index)
            st.success(f"æ–‡æ¡£ {uploaded_file.name} å‘é‡åŒ–å¹¶æ·»åŠ åˆ°ç´¢å¼•ä¸­ï¼")

    # æ˜¾ç¤ºå·²å¤„ç†çš„æ–‡ä»¶å¹¶æ·»åŠ åˆ é™¤æŒ‰é’®
    st.subheader("å·²å¤„ç†æ–‡æ¡£:")
    for file_name in list(st.session_state.file_indices.keys()):
        col1, col2 = st.columns([3, 1])
        with col1:
            st.write(f"â€¢ {file_name}")
        with col2:
            if st.button("åˆ é™¤", key=f"delete_{file_name}"):
                del st.session_state.file_indices[file_name]
                delete_index(file_name)
                st.success(f"æ–‡æ¡£ {file_name} å·²åˆ é™¤ï¼")
                st.rerun()

    # æ·»åŠ å…³é”®è¯æœç´¢åŠŸèƒ½
    st.subheader("å…³é”®è¯æœç´¢")
    search_keywords = st.text_input("è¾“å…¥å…³é”®è¯ï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼‰")
    if search_keywords:
        keywords = search_keywords.split()
        relevant_docs = search_documents(keywords, st.session_state.file_indices)
        if relevant_docs:
            st.write("ç›¸å…³æ–‡æ¡£ï¼š")
            for doc in relevant_docs:
                st.write(f"â€¢ {doc}")
            st.session_state.relevant_docs = relevant_docs
        else:
            st.write("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ã€‚")
            st.session_state.relevant_docs = None

    # é—®ç­”éƒ¨åˆ†
    st.subheader("é—®ç­”")
    query = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜")
    
    if query:
        try:
            with st.spinner("æ­£åœ¨æŸ¥æ‰¾ç­”æ¡ˆ..."):
                responses, sources, excerpt = rag_qa(
                    query, 
                    st.session_state.file_indices,
                    st.session_state.get('relevant_docs')
                )
                
                # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
                left_col, right_col = st.columns(2)
                
                # å·¦ä¾§æ˜¾ç¤ºChatGPTå›ç­”
                with left_col:
                    st.markdown("### ChatGPTå›ç­”")
                    if responses and 'chatgpt' in responses and responses['chatgpt']:
                        st.markdown(f"""
                        <div style='background-color: #f0f2f6; padding: 15px; border-radius: 5px;'>
                            {responses['chatgpt']}
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.error("è·å–ChatGPTå›ç­”å¤±è´¥")
                
                # å³ä¾§æ˜¾ç¤ºDeepseekå›ç­”
                with right_col:
                    st.markdown("### Deepseekå›ç­”")
                    if responses and 'deepseek' in responses and responses['deepseek']:
                        st.markdown(f"""
                        <div style='background-color: #e6f3ff; padding: 15px; border-radius: 5px;'>
                            {responses['deepseek']}
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.error("è·å–Deepseekå›ç­”å¤±è´¥")
                
                # æ˜¾ç¤ºæ¥æºæ–‡æ¡£
                if sources:
                    st.markdown("### æ¥æºæ–‡æ¡£")
                    for file_name, context in sources:
                        with st.expander(f"ğŸ“„ {file_name}"):
                            st.write(context)
                
                # æ˜¾ç¤ºç›¸å…³åŸæ–‡
                if excerpt:
                    st.markdown("### ç›¸å…³åŸæ–‡")
                    st.markdown(f"""
                    <div style='background-color: #f8f9fa; padding: 15px; border-radius: 5px; border: 1px solid #dee2e6;'>
                        {excerpt}
                    </div>
                    """, unsafe_allow_html=True)

        except Exception as e:
            st.error(f"å¤„ç†é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback
            st.error(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
            st.info("è¯·æ£€æŸ¥APIé…ç½®æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ç¨åé‡è¯•")

if __name__ == "__main__":
    main() 